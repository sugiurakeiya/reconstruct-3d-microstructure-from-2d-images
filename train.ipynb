{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Project_name = 'DP1_0106'\n",
    "Project_dir = 'Trained_Generators/DP1'\n",
    "Training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdr(proj,proj_dir,Training):\n",
    "    \"\"\"\n",
    "    When training, creates a new project directory or overwrites an existing directory according to user input. When testing, returns the full project path\n",
    "    :param proj: project name\n",
    "    :param proj_dir: project directory\n",
    "    :param Training: whether new training run or testing image\n",
    "    :return: full project path\n",
    "    \"\"\"\n",
    "    pth = proj_dir + '/' + proj\n",
    "    if Training:\n",
    "        try:\n",
    "            os.mkdir(pth)\n",
    "            return pth + '/' + proj\n",
    "        except FileExistsError:\n",
    "            print('Directory', pth, 'already exists. Enter new project name or hit enter to overwrite')\n",
    "            new = input()\n",
    "            if new == '':\n",
    "                return pth + '/' + proj\n",
    "            else:\n",
    "                pth = mkdr(new, proj_dir, Training)\n",
    "                return pth\n",
    "        except FileNotFoundError:\n",
    "            print('The specifified project directory ' + proj_dir + ' does not exist. Please change to a directory that does exist and again')\n",
    "            sys.exit()\n",
    "    else:\n",
    "        return pth + '/' + proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = \"inputs/DP1_xy.png\"\n",
    "zx = \"inputs/DP1_xz.png\"\n",
    "yz_90_degree_right_rotate = \"inputs/DP1_yz.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_paths = [xy, zx, yz_90_degree_right_rotate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"data/celeba\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 0\n",
    "\n",
    "# Batch size during training\n",
    "g_batch_size, d_batch_size = 8, 8\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
    "l = 64\n",
    "\n",
    "# Number of channels in the training images.\n",
    "nc = 2\n",
    "\n",
    "# Number of channels in z latent vector\n",
    "nz = 64\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "lz = 4\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 1\n",
    "\n",
    "# Learning rate for optimizers\n",
    "g_lr, d_lr = 0.0001, 0.0001\n",
    "\n",
    "# Beta1 and Beta2 hyperparam for Adam optimizers\n",
    "g_betas, d_betas = (.9, .99), (.9, .99)\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = mkdr(Project_name, Project_dir, Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_set_xyz = []\n",
    "for input_image_path in input_image_paths:\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    if len(input_image.shape) > 2:\n",
    "        input_image = input_image[:, :, 0]\n",
    "    h, w = input_image.shape[0], input_image.shape[1]\n",
    "    \n",
    "    phases = np.unique(input_image)\n",
    "    train_images_set = np.empty([32 * 900, len(phases), l, l]) ###\n",
    "    for i in range(32 * 900):\n",
    "        x = np.random.randint(1, h-l-1)\n",
    "        y = np.random.randint(1, w-l-1)\n",
    "        for count, phase in enumerate(phases):\n",
    "            image_i = np.zeros([l, l])\n",
    "            image_i[input_image[x:x+l, y:y+l] == phase] = 1\n",
    "            train_images_set[i, count, :, :] = image_i\n",
    "        \n",
    "    train_images_set_tensor = torch.utils.data.TensorDataset(torch.FloatTensor(train_images_set))\n",
    "    train_images_set_xyz.append(train_images_set_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainloader = torch.utils.data.DataLoader(train_images_set_xyz[0], batch_size=g_batch_size, shuffle=True, num_workers=workers)\n",
    "y_trainloader = torch.utils.data.DataLoader(train_images_set_xyz[1], batch_size=g_batch_size, shuffle=True, num_workers=workers)\n",
    "z_trainloader = torch.utils.data.DataLoader(train_images_set_xyz[2], batch_size=g_batch_size, shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lays = 5\n",
    "df, gf = [nc, ndf, ndf*2, ndf*4, ndf*8, 1], [nz, ngf*16, ngf*8, ngf*4, ngf*2, nc]\n",
    "dk, gk = [4]*lays, [4]*lays\n",
    "ds, gs = [2]*lays, [2]*lays\n",
    "dp, gp = [1, 1, 1, 1, 0], [2, 2, 2, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, gf, gk, gs, gp):\n",
    "        super(Generator, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        for lay, (k,s,p) in enumerate(zip(gk, gs, gp)):\n",
    "            self.convs.append(nn.ConvTranspose3d(gf[lay], gf[lay+1], k, s, p, bias=False))\n",
    "            self.bns.append(nn.BatchNorm3d(gf[lay+1]))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for conv, bn in zip(self.convs[:-1], self.bns[:-1]):\n",
    "            x = F.relu_(bn(conv(x)))\n",
    "        x = torch.softmax(self.convs[-1](x), 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, df, dk, ds, dp):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for lay, (k, s, p) in enumerate(zip(dk, ds, dp)):\n",
    "            self.convs.append(nn.Conv2d(df[lay], df[lay + 1], k, s, p, bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = F.relu_(conv(x))\n",
    "        x = self.convs[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data, batch_size, l, device, gp_lambda,nc):\n",
    "    \"\"\"\n",
    "    calculate gradient penalty for a batch of real and fake data\n",
    "    :param netD: Discriminator network\n",
    "    :param real_data:\n",
    "    :param fake_data:\n",
    "    :param batch_size:\n",
    "    :param l: image size\n",
    "    :param device:\n",
    "    :param gp_lambda: learning parameter for GP\n",
    "    :param nc: channels\n",
    "    :return: gradient penalty\n",
    "    \"\"\"\n",
    "    #sample and reshape random numbers\n",
    "    alpha = torch.rand(batch_size, 1, device = device)\n",
    "    alpha = alpha.expand(batch_size, int(real_data.nelement() / batch_size)).contiguous()\n",
    "    alpha = alpha.view(batch_size, nc, l, l)\n",
    "\n",
    "    # create interpolate dataset\n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    #pass interpolates through netD\n",
    "    disc_interpolates = netD(interpolates)\n",
    "    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size(), device = device),\n",
    "                              create_graph=True, only_inputs=True)[0]\n",
    "    # extract the grads and calculate gp\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * gp_lambda\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientPenalty(nn.Module):\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, f: torch.Tensor):\n",
    "        batch_size = x.shape[0]\n",
    "        gradients, *_ = torch.autograd.grad(outputs=f,\n",
    "                                            inputs=x,\n",
    "                                            grad_outputs=f.new_ones(f.shape),\n",
    "                                            create_graph=True)\n",
    "        gradients = gradients.reshape(batch_size, -1)\n",
    "        norm = gradients.norm(2, dim=-1)\n",
    "        return 10 * torch.mean((norm - 1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if(torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(gf, gk, gs, gp).to(device)\n",
    "if (device.type == \"cuda\") and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "optG = torch.optim.Adam(netG.parameters(), lr=g_lr, betas=g_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "netDs = []\n",
    "optDs = []\n",
    "for i in range(3):\n",
    "    netD = Discriminator(df, dk, ds, dp)\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu))).to(device)\n",
    "    netDs.append(netD)\n",
    "    optDs.append(torch.optim.Adam(netDs[i].parameters(), lr=d_lr, betas=d_betas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generator_loss(data, labels, pth, name):\n",
    "    for data, label in zip(data, labels):\n",
    "        plt.plot(data, label=label)\n",
    "    plt.title(\"Generator Loss\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(pth + \"_\" + name)\n",
    "    plt.close()\n",
    "\n",
    "def plot_discriminator_loss(data, labels, pth, name):\n",
    "    for data, label in zip(data, labels):\n",
    "        plt.plot(data, label=label)\n",
    "    plt.title(\"Discriminator Loss\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(pth + \"_\" + name)\n",
    "    plt.close()\n",
    "\n",
    "def plot_wasserstein_distance(data, labels, pth, name):\n",
    "    for data, label in zip(data, labels):\n",
    "        plt.plot(data, label=label)\n",
    "    plt.title(\"Wasserstein Distance\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"wasserstein distance\")\n",
    "    plt.legend()\n",
    "    plt.savefig(pth + \"_\" + name)\n",
    "    plt.close()\n",
    "\n",
    "def plot_gradient_penalty(data, labels, pth, name):\n",
    "    for data, label in zip(data, labels):\n",
    "        plt.plot(data, label=label)\n",
    "    plt.title(\"Gradient Penalty\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"gradient penalty\")\n",
    "    plt.legend()\n",
    "    plt.savefig(pth + \"_\" + name)\n",
    "    plt.close()\n",
    "    \n",
    "def plot_real_fake_loss(data, labels, pth, name):\n",
    "    for data, label in zip(data, labels):\n",
    "        plt.plot(data, label=label)\n",
    "    plt.title(\"Discriminator Outputs\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(pth + \"_\" + name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "finish\n",
      "finish\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     gradient_penalty \u001b[39m=\u001b[39m calc_gradient_penalty(netD, real_2d_images, fake_2d_images[:g_batch_size], g_batch_size, l, device, \u001b[39m10\u001b[39m, nc)\n\u001b[1;32m     25\u001b[0m     errD \u001b[39m=\u001b[39m errD_fake \u001b[39m-\u001b[39m errD_real \u001b[39m+\u001b[39m gradient_penalty\n\u001b[0;32m---> 26\u001b[0m     errD\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     27\u001b[0m     optD\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m d_real_output_list\u001b[39m.\u001b[39mappend(errD_real\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Code/reconstruct-3d-microstructure-from-2d-images/.env/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/Code/reconstruct-3d-microstructure-from-2d-images/.env/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "d_real_output_list = []\n",
    "d_fake_output_list = []\n",
    "gradient_penality_list = []\n",
    "wasserstein_distance_list = []\n",
    "g_loss_list = []\n",
    "d_loss_list = []\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    start_epoch_time = time.time()\n",
    "    for iteration, (x_train_images, y_train_images, z_train_images) in enumerate(zip(x_trainloader, y_trainloader, z_trainloader), 1):\n",
    "        train_2d_images_set = [x_train_images, y_train_images, z_train_images] ###\n",
    "        \n",
    "        noise = torch.randn(d_batch_size, nz, lz, lz, lz, device=device)\n",
    "        fake_3d_image = netG(noise).detach()\n",
    "        \n",
    "        # Discriminator\n",
    "        for train_images_set, netD, optD, d1, d2, d3 in zip(train_2d_images_set, netDs, optDs, [2,3,4], [3,2,2], [4,4,3]):\n",
    "            netD.zero_grad()\n",
    "            real_2d_images = train_images_set[0].to(device)\n",
    "            errD_real = netD(real_2d_images).view(-1).mean() ###\n",
    "            fake_2d_images = fake_3d_image.permute(0, d1, 1, d2, d3).reshape(l * d_batch_size, nc, l, l)\n",
    "            errD_fake = netD(fake_2d_images).mean() ###\n",
    "            gradient_penalty = calc_gradient_penalty(netD, real_2d_images, fake_2d_images[:g_batch_size], g_batch_size, l, device, 10, nc)\n",
    "            errD = errD_fake - errD_real + gradient_penalty\n",
    "            errD.backward()\n",
    "            optD.step()\n",
    "        d_real_output_list.append(errD_real.item())\n",
    "        d_fake_output_list.append(errD_fake.item())\n",
    "        wasserstein_distance_list.append(errD_real.item() - errD_fake.item())\n",
    "        gradient_penality_list.append(gradient_penalty.item())\n",
    "        d_loss_list.append(errD.item())\n",
    "         \n",
    "        # Generator ###\n",
    "        if iteration % 5 == 0:\n",
    "            netG.zero_grad()\n",
    "            errG = 0\n",
    "            \n",
    "            noise = torch.randn(g_batch_size, nz, lz, lz, lz, device=device)\n",
    "            fake_3d_images = netG(noise) ###\n",
    "\n",
    "            for netD, d1, d2, d3 in zip(netDs, [2, 3, 4], [3, 2, 2], [4, 4, 3]):\n",
    "                fake_2d_images = fake_3d_image.permute(0, d1, 1, d2, d3).reshape(l * g_batch_size, nc, l, l)\n",
    "                errG_fake = netD(fake_2d_images)\n",
    "                errG -= errG_fake.mean()\n",
    "            errG.backward()\n",
    "            optG.step()\n",
    "            g_loss_list.append(errG.item())\n",
    "\n",
    "        if iteration % 25 == 0:\n",
    "            netG.eval()\n",
    "            with torch.no_grad():\n",
    "                torch.save(netG.state_dict(), pth + \"_generator.pth\")\n",
    "                torch.save(netD.state_dict(), pth + \"_discriminator.pth\")\n",
    "                plot_real_fake_loss([d_real_output_list, d_fake_output_list], [\"Real\", \"Fake\"], pth, \"d_output_graoh\")\n",
    "                plot_wasserstein_distance([wasserstein_distance_list], [\"Wasserstein Distance\"], pth, \"wd_graph\")\n",
    "                plot_gradient_penalty([gradient_penality_list], [\"Gradient Penalty\"], pth, \"gp_graph\")\n",
    "                plot_discriminator_loss([d_loss_list], [\"Discriminator\"], pth, \"d_loss_graph\")\n",
    "                plot_generator_loss([g_loss_list], [\"Generator\"], pth, \"g_loss_graph\")\n",
    "            netG.train()\n",
    "            \n",
    "    print(\n",
    "    \"進捗率: {0} % \\n\"\n",
    "    \"現在のエポック: {1}/{2} \\n\"\n",
    "    \"1エポックに要した時間: {3} s/1epoch \\n\"\n",
    "    \"これまでに要した時間: {4} \\n\"\n",
    "    .format(\n",
    "        round((epoch) * 100 / num_epochs , 1),\n",
    "        epoch,\n",
    "        num_epochs,\n",
    "        datetime.timedelta(seconds=time.time() - start_epoch_time),\n",
    "        datetime.timedelta(seconds=(time.time() - start_time))))\n",
    "    print(\"-\"*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e7ec90a9c66af92256ff8b2894ac693212b39523d6b27e5c9a75ebfc957ff9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
